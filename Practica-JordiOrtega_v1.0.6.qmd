---
format: html
editor: visual
  markdown: 
    wrap: 72
---

Vasmos a cargar el dataset de AirBnB descargado de [aquí](https://public.opendatasoft.com/explore/dataset/airbnb-listings/export/?disjunctive.host_verifications&disjunctive.amenities&disjunctive.features&q=Madrid&dataChart=eyJxdWVyaWVzIjpbeyJjaGFydHMiOlt7InR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQ09VTlQiLCJ5QXhpcyI6Imhvc3RfbGlzdGluZ3NfY291bnQiLCJzY2llbnRpZmljRGlzcGxheSI6dHJ1ZSwiY29sb3IiOiJyYW5nZS1jdXN0b20ifV0sInhBeGlzIjoiY2l0eSIsIm1heHBvaW50cyI6IiIsInRpbWVzY2FsZSI6IiIsInNvcnQiOiIiLCJzZXJpZXNCcmVha2Rvd24iOiJyb29tX3R5cGUiLCJjb25maWciOnsiZGF0YXNldCI6ImFpcmJuYi1saXN0aW5ncyIsIm9wdGlvbnMiOnsiZGlzanVuY3RpdmUuaG9zdF92ZXJpZmljYXRpb25zIjp0cnVlLCJkaXNqdW5jdGl2ZS5hbWVuaXRpZXMiOnRydWUsImRpc2p1bmN0aXZlLmZlYXR1cmVzIjp0cnVlfX19XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D&location=16,41.38377,2.15774&basemap=jawg.streets)

![](descargar.png)

```{r}
airbnb<-read.csv('airbnb-listings.csv',sep = ';')
options(repr.plot.height=4,repr.plot.width=6,repr.plot.res = 300)
```

1.  Vamos a quedarnos con las columnas de mayor interés: 'City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude' Nos quedarmos solo con las entradas de Madrid para Room.Type=="Entire home/apt" y cuyo barrio (Neighbourhood) no está vacio '' Podemos eliminar las siguientes columnas que ya no son necesarias: "Room.Type",'City' Llama a nuevo dataframe df_madrid.

```{r}
# Observamos volumetría y verificamos que no existen IDs duplicados 
nrow(airbnb)==length(unique(airbnb$ID))
cat("el dataset dispone de", nrow(airbnb),"pisos \n")
```

```{r}
df_madrid <- airbnb[which(airbnb$City=="Madrid" & airbnb$Room.Type=="Entire home/apt" & airbnb$Neighbourhood!=""),]

df_madrid <- df_madrid[, c('Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude')]

cat("el df_madrid dispone de", nrow(df_madrid),"pisos \n")

```

------------------------------------------------------------------------

2.  Crea una nueva columna llamada Square.Meters a partir de Square.Feet. Recuerda que un pie cuadrado son 0.092903 metros cuadrados.

```{r}
df_madrid$Square.Meters <- df_madrid$Square.Feet*0.092903
```

------------------------------------------------------------------------

3.  ¿Que porcentaje de los apartamentos no muestran los metros cuadrados? Es decir, ¿cuantos tienen NA en Square.Meters?

```{r}
Square.Meters_na <- sum(is.na(df_madrid$Square.Meters))/nrow(df_madrid)*100
Square.Meters_na
```

------------------------------------------------------------------------

4.  De todos los apartamentos que tienen un valor de metros cuadrados diferente de NA ¿Que porcentaje de los apartamentos tienen 0 metros cuadrados?

```{r}
# Descartamos las observaciones con Square.Meters=NA
df_madrid_informed <- df_madrid[which(!is.na(df_madrid$Square.Meters)),]

# Calculamos el porcentaje de los Square.Meters=0 VS losinformados
Square.Meters_zero <- sum(df_madrid_informed$Square.Meters==0)/nrow(df_madrid_informed)*100
Square.Meters_zero

```

------------------------------------------------------------------------

5.  Reemplazar todos los 0m\^2 por NA

```{r}
df_madrid$Square.Meters[df_madrid$Square.Meters==0] <- NA
```

------------------------------------------------------------------------

Hay muchos NAs, vamos a intentar crear un modelo que nos prediga cuantos son los metros cuadrados en función del resto de variables para tratar de rellenar esos NA. Pero **antes de crear el modelo** vamos a hacer: \* pintar el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más. \* crear una variable sintética nueva basada en la similitud entre barrios que usaremos en nuestro modelo.

6.  Pinta el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más

```{r}
library("ggplot2")

ggplot(df_madrid, aes(x = Square.Meters)) +
  geom_histogram(binwidth = 10, fill = "orange", color = "black") +
  ylab('Número de casos') + 
  xlab('Metros Cuadrados') +
  ggtitle("Número de pisos por metro cuadrado") +
  theme_minimal()+
  stat_bin(binwidth = 10, geom = "text", aes(label = ifelse(..count.. > 0, ..count.., "")), vjust = -0.5, color = "black")
```

------------------------------------------------------------------------

7.  Asigna el valor NA a la columna Square.Meters de los apartamentos que tengan menos de 20 m\^2

```{r}
df_madrid$Square.Meters[df_madrid$Square.Meters<20] <- NA

# Se decide no descartar pisos de muchos m2 ya que son valores posibles/reales y mantenemos así la transversalidad del modelo. Por el contrario, se ignoran las observaciones menores a 20m2 por considerarse habitaciones (y no pisos)
```

------------------------------------------------------------------------

8.  Existen varios Barrios que todas sus entradas de Square.Meters son NA, vamos a eliminar del dataset todos los pisos que pertenecen a estos barrios.

```{r}
library(tidyverse)

# Creamos una variable 'flag' para determinar que barrios cumplen la condición del enunciado
df_madrid_cleaned <- df_madrid |> group_by(Neighbourhood) |> summarise(numero_casos=n(), numero_na = sum(is.na(Square.Meters)),Neighbourhood_lg = n()==sum(is.na(Square.Meters)))
df_madrid_cleaned


```

```{r}
# Filtramos según el flag creado
df_madrid_cleaned <- df_madrid_cleaned[which(df_madrid_cleaned$Neighbourhood_lg==FALSE),]
df_madrid_cleaned
```

```{r}
# Aceptamos el df_madrid original (df_madrid) pero sólo con aquellos barrios que cumplen la condicion descrita en el paso anterior. Dejamos nuevo nombre de dataframe para su revisión.
df_madrid_filtered <- df_madrid |>
  semi_join(df_madrid_cleaned, by = "Neighbourhood")
```

9.  ¿Tienen todos los barrios los mismos metros cuadrados de media? ¿Con que test lo comprobarías?

```{r}
# Renombramos el nombre a df_madrid para seguir con la practica
df_madrid <- df_madrid_filtered

# Gráfico boxplot para tener un preanalisis de los datos. Conclusiones preliminaes:
   # Observamos medianas diferentes (las lineas negras de los distintos barrios estan desalineadas)
   # Dispersión de datos distinta entre barrios (rangos intercuartílicos diferentes)
   # Observamos valores atípicos (puntos fera de los bigotes)
   # Vemos diferentes distribuciones (tamaño de los bigotes)
# Conclusión: la asimetría de cajas y bigotes, los valores extremos y la comparación de la altura de las cajas nos empuja a pensar que las medias serán distinas.
ggplot(df_madrid, aes(x = Neighbourhood, y = Square.Meters)) +
  geom_boxplot(fill = "orange", color = "black") +
  ylab('Metros cuadrados') + 
  xlab('Barrios') +
  ggtitle("Distribución de metros cuadrados por barrio") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

```{r}
# Para poder ser concluyentes e identificar si los barrios siguen una distribució normal se realiza un test de Shapiro. Se realiza el shapiro con los barrios con muestras suficientes para este modelo (>=3 y <=5000)

# Creamos el conteo de observaciones validas de cada barrio
df_madrid_counter <- df_madrid |>
  group_by(Neighbourhood) |>
  summarise(
    numero_casos = n(),
    numero_na = sum(is.na(Square.Meters)),
    observaciones = n() - sum(is.na(Square.Meters))
  )

# Contamos el número de barrios útiles para el test. no se requiere comprobación para el extremo superior.
summary_counts <- df_madrid_counter |>
  mutate(categoria = ifelse(observaciones >= 3, ">3 muestras válidas", "<3 muestras validas")) |>
  count(categoria)

# Seleccionamos los barrios que tienen suficientes muestras validas
df_madrid_counter_filtered <- df_madrid_counter |>
  filter(observaciones >= 3)

# Mostrar resultados
print(summary_counts)
print(df_madrid_counter_filtered)
```

```{r}
# Filtramos el df_madrid sólo con los barrios válidos para el test de Shapiro
df_madrid <- df_madrid |>
  semi_join(df_madrid_counter_filtered, by = "Neighbourhood")

# Creamos un dataframe que usaremos en ejercicios posteriores (último punto de la practica)
df_madrid_playground <- df_madrid

# Filtramos las observaciones que contienen el valor NA antes de aplicar el test
df_madrid <- df_madrid |>
  filter(!is.na(Square.Meters))

```

```{r}
# Aplicamos el test
shapiro_test_group <- function(df, group_col, value_col) {
  df |>
    group_by(across(all_of(group_col))) |>
    summarize(
      shapiro_statistic = shapiro.test(get(value_col))$statistic,
      shapiro_p_value = shapiro.test(get(value_col))$p.value,
      .groups = 'drop'
    )
}

shapiro_results <- shapiro_test_group(df_madrid, 'Neighbourhood', 'Square.Meters')

print(shapiro_results)
# La H0 asume que todos los datos siguen una distribución normal. En general para todos los barrios se aprecia un estadístico 'cercano' a 1 (aunque no disponemos de un umbral que nos permita posicionarnos firmemente). 
# Los barrios con pvalor < 0,05 permiten rechazar la Ho y los datos sugieren que NO siguen una distribución normal.

# De los 15 barrios con los que se ha podido realizar el test en 5 su pvalor es menor a 0.05 y por este motivo haremos un un test Kruskal-Wallis

```

```{r}
# Se calcula el mismo test mediante un bucle for
df_madrid$Neighbourhood <- as.factor(df_madrid$Neighbourhood) 

for (v in levels(df_madrid$Neighbourhood)){
    print(paste("Neighbourhood:",v,"pvalue,",
                shapiro.test(df_madrid$Square.Meters[df_madrid$Neighbourhood==v])$p.value))
}
```

```{r}
# Realizamos el test de Kruskal-Wallis
kruskal_test <- kruskal.test(Square.Meters ~ Neighbourhood, data = df_madrid)

print(kruskal_test)

# Hay diferencias significativas en las medianas de los grupos comparados

```

```         
```

------------------------------------------------------------------------

10. Vamos a agrupar los barrios por metros cuadrados. Podemos usar una matriz de similaridad de Tukey. Muestra como de similares o diferentes son los barrios si nos fijámos únicamente en los metros cuadrados de los pisos. ¿Como se diferencia la media del Barrio A al Barrio B? (Es decir, cual sería el pvalor suponiendo una H0 en la que las medias son iguales)

```{r}
# H0 las medias son iguales
# Para realizar un Tukey parece conveniente partir de un ANOVA
anova_test <- aov(Square.Meters ~ Neighbourhood, data = df_madrid)
summary(anova_test)
print(anova_test)

#El test ANOVA es significativo con un pvalor <0.05, esto nos indica que los barrios son diferentes entre sí. Para determinar 'cuales' es conveniente realizar un test de Tukey.
```

```{r}
tukey_test <- TukeyHSD(anova_test)
print(tukey_test)
# Encontramos barrios con mucha similitud en su media de m2, pero también otros bien distintos como:
# Cortes-Castellana       
# Embajadores-Castellana 
```

```{r}
#Construimos una matriz simétrica donde cada valor es el pvalor de las comparaciones entre barrios
tky <- tukey_test
tky.result <- data.frame(tky$Neighbourhood)
cn <- sort(unique(df_madrid$Neighbourhood))
resm <- matrix(NA, length(cn),length(cn))
rownames(resm) <- cn
colnames(resm) <- cn
resm[lower.tri(resm) ] <- round(tky.result$p.adj,4)
resm[upper.tri(resm) ] <- t(resm)[upper.tri(resm)] 
diag(resm) <- 1
resm
```

```{r}
library(ggplot2)
library(reshape2)

# Dibujamos la matriz que muestra como de similares o diferentes son los barrios si nos fijámos únicamente en los metros cuadrados de los pisos.
dfResm <- melt(resm)
ggplot(dfResm, aes(x=Var1, y=Var2, fill=value))+
  geom_tile(colour = "black")+
  geom_text(aes(label=paste(round(value*100,0),"%")),size = 3) +
  scale_fill_gradient(low = "white",high = "orange")+
  ylab("Class")+xlab("Class")+theme_bw()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position="none")

#se confirma la peculiaridad del barrio de la castellana,SOL, y de San Blas
```

------------------------------------------------------------------------

11. En el punto anterior has creado una matriz de p-valores que indica como de parecidos son dos barrios. Si su pvalor es alto significa que los barrios son diferentes, si es bajo significa que los barrios se parecen. Esta matriz la podemos usar como matriz de distancia si restamos el pvalor a 1. Es decir si usamos como distancia 1-pvalor. De esta forma barrios con un pvalor alto tendrán una distancia mayor que aquellos con un pvalor bajo. Usando esta última métrica como matriz de distancias dibuja un dendrograma de los diferentes barrios.

```{r}
# Calculamos el dendograma teniendo en cuenta la distancia entre barrios

d <- as.dist(1-resm)
hc <- hclust(d,method="complete")
hcd <- as.dendrogram(hc)
par(cex=0.9)
plot(hcd)
```

------------------------------------------------------------------------

10. ¿Que punto de corte sería el aconsejable?, ¿cuantos clusters aparecen?

```{r}
# Cortamos por el valor 0.4 y nos quedamos con 3 clusters
clusters <- cutree(hc,h=0.4)

clusters
```

------------------------------------------------------------------------

11. Vamos a crear una nueva columna en el dataframe df_madrid con un nuevo identificador marcado por los clusters obtenidos. Esta columna la llamaremos neighb_id

```{r}
# Asignamos el nombre de los barrios para permitir el join
df_cluster <- data.frame(clusters)
df_cluster$Neighbourhood <- rownames(df_cluster)
head(df_cluster)
```

```{r}
# Ampliamos el df_madrid con la nueva variables clusters
df_madrid_cl <- df_cluster |> inner_join(df_madrid, by='Neighbourhood')
df_madrid_cl
#ahora el df_cluster ya contiene el cluster por cada observación
```

```{r}
# Convertimos la variables a factor
df_madrid_cl$clusters <- as.factor(df_madrid_cl$clusters)
```

```{r}
# Cambiamos el nombre a "neighb_id"
colnames(df_madrid_cl)[which(colnames(df_madrid_cl) == "clusters")] <- "neighb_id"
df_madrid_cl
```

------------------------------------------------------------------------

12. Vamos a crear dos grupos, uno test y otro train.

```{r}
# Renombramos el dataset como df_madrid
df_madrid <- df_madrid_cl

#primero eliminamos columnas que no tienen un impacto en el modelo
df_madrid <- df_madrid |> select(-Neighbourhood,-Square.Feet, -Latitude, -Longitude)
df_madrid
```

```{r}
# Con el objetivo de tener un modelo robusto, aceptamos la limitación de exigir que las nuevas observaciones a participar en el modelo contengan todas las variables cumplimentadas.
# Podemos aplicar na.omit porque todas las columnas van a participar en el modelo (para posteriores ajustes se tiene que reconsiderar este punto)
df_madrid <- na.omit(df_madrid)
```

```{r}
# Nos quedamos con el 70% para train y el 30% de registros para test
df_madrid_train <- sample(1:nrow(df_madrid),round(nrow(df_madrid)*0.7))
df_madrid.train <- df_madrid[df_madrid_train,]
df_madrid.test <- df_madrid[-df_madrid_train,]
df_madrid.test <- df_madrid.test |> select(-Square.Meters)
```

------------------------------------------------------------------------

13. Tratamos de predecir los metros cuadrados en función del resto de columnas del dataframe.

```{r}
model <- lm(Square.Meters~., data=df_madrid.train)
summary(model)
# Del análisis del resultado del modelo se pueden plantear distintas acciones para simplificar el modelo y afinar la predicción. Conclusiones y posibles acciones:
    # Bedrooms y neight_id=3 tiene un efecto grande en la variable dependiente
    # Para simplificar el modelo podríamos eliminar la variable 'Accommodates'
    # Prueba y error descartando variables para ver como impactan en el modelo
```

```{r}
# Predecimos los valores para test
predicciones <- predict(model, newdata = df_madrid.test)
```

------------------------------------------------------------------------

14. Evaluar la calidad de vuestro modelo

```{r}
# seleccionamos los valores reales de Square.Meters
valores_reales <- df_madrid$Square.Meters[-df_madrid_train]

# Calcularmos el error de las predicciones
errores <- predicciones - valores_reales
```

```{r}
# Evaluamos la precisión del modelo
mae <- mean(abs(errores))
mse <- mean(errores^2)
rmse <- sqrt(mse)
r_squared <- summary(model)$r.squared

# Promedio de las diferencias absolutas entre los valores predichos y los valores reales.
cat("MAE:", mae, "\n")
# Promedio de los cuadrados de las diferencias entre los valores predichos y los valores reales. Penaliza más fuertemente los errores grandes debido al cuadrado de las diferencias
cat("MSE:", mse, "\n")
# Es la raíz cuadrada del MSE, devolviendo el error medio en las mismas unidades que el objetivo.
cat("RMSE:", rmse, "\n")
# Proporción de la varianza en la variable dependiente que es explicada por el modelo. Varía entre 0 y 1, donde 1 indica que el modelo explica toda la variabilidad de la respuesta.
cat("R-squared:", r_squared, "\n")
```

```{r}
#MAE: el modelo se desvía en 15m2
#MSE: media de los errores al cuadrado
#RMSE: 19m2 de error promedio, similar a MAE pero penaliza errores grandes
#R-squared: el 70% de la variabilidad de Square.Meters se explica por el modelo
```

------------------------------------------------------------------------

15. Si tuvieramos un anuncio de un apartamento para 6 personas (Accommodates), con 1 baño, con un precio de 80€/noche y 3 habitaciones en el barrio de Sol, con 3 camas y un review de 80. ¿Cuantos metros cuadrados tendría? Si tu modelo necesita algúna variable adicional puedes inventartela dentro del rango de valores del dataset. ¿Como varía sus metros cuadrados con cada habitación adicional?

```{r}
prediccion_apartamento <- predict(model, newdata = data.frame(Accommodates=6,Bathrooms=1,Price=80,Bedrooms=3,neighb_id='1',Beds=2,Guests.Included=6,Extra.People=10,Review.Scores.Rating=90))
prediccion_apartamento
```

```{r}
prediccion_apartamento <- predict(model, newdata = data.frame(Accommodates=6,Bathrooms=1,Price=80,Bedrooms=4,neighb_id='1',Beds=2,Guests.Included=6,Extra.People=10,Review.Scores.Rating=90))
prediccion_apartamento
```

------------------------------------------------------------------------

16. Rellenar los Square.Meters con valor NA con el estimado con el modelo anterior.

```{r}
# En un apartado anterior, guardamso el dataframe: df_madrid_playground
# Asignamos el cluster, pasamos a factor y cambiamos el nombre de la columna a neigh_id
df_madrid_pd_cl <- df_cluster |> inner_join(df_madrid_playground, by='Neighbourhood')
df_madrid_pd_cl$clusters <- as.factor(df_madrid_pd_cl$clusters)
colnames(df_madrid_pd_cl)[which(colnames(df_madrid_pd_cl) == "clusters")] <- "neighb_id"
# Seleccionamos de df_madrid_pd_cl sólo los neighbourhoods para los que el modelo ha entrenado.
df_madrid_pd_cl <- df_madrid_pd_cl |>
  semi_join(df_madrid_cleaned, by = "Neighbourhood")
# Seleccionamos las variables para las que ha sido entrenado el modelo (ojo si variable NA el modelo ignorará la observación)
df_madrid_pd_cl <- df_madrid_pd_cl |> select(-Neighbourhood,-Square.Feet, -Latitude, -Longitude)

# Asignamos el valor que diga el model:
df_madrid_pd_cl$Square.Meters[is.na(df_madrid_pd_cl$Square.Meters)] <- predict(model,df_madrid_pd_cl[is.na(df_madrid_pd_cl$Square.Meters),])

print(df_madrid_pd_cl)
```

------------------------------------------------------------------------
